# Deep_Learning_Seq2Seq
Sequence to Sequence (often abbreviated to seq2seq) models is a special class of Recurrent Neural Network architectures that we typically use (but not restricted) to solve complex Language problems like Machine Translation, Question Answering, creating Chatbots, Text Summarization, etc.

Seq2Seq is a type of Encoder-Decoder model using RNN. It can be used as a model for machine interaction and machine translation.

By learning a large number of sequence pairs, this model generates one from the other.

## About:

Automatic text summarization (ATS) has become very popular among researchers because it involves generating a smaller subset of text from the main text. This subset represents the textâ€™s entire and main idea. Natural Language Processing and Machine Learning are critical applications of ATS. Summarizations are classified into two types based on how they are generated: extractive and abstractive. In this project, we have implemented the Hindi text summarization, on which very little work has been done to date.
